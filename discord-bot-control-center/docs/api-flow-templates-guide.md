# 複数API連携フローテンプレート設定ガイド

このドキュメントでは、Discord Bot Control Centerで利用可能な複数API連携フローテンプレートの詳細な設定項目について説明します。

## 目次

1. [音声認識＆要約](#音声認識要約)
2. [リンク分析＆図解化](#リンク分析図解化)
3. [検索＆図解化](#検索図解化)
4. [YouTube動画分析](#youtube動画分析)
5. [会議議事録作成](#会議議事録作成)
6. [翻訳＆要約](#翻訳要約)
7. [画像生成＆説明](#画像生成説明)

---

## 音声認識＆要約

このフローは、音声ファイルをテキストに変換し、その内容を要約します。

### ステップ1: 音声認識（OpenAI Whisper）

| 設定項目 | 説明 | デフォルト値 |
|---------|------|------------|
| モデル | 使用する音声認識モデル | whisper-1 |
| 温度 | 生成の多様性（低いほど決定的） | 0.0 |
| 言語 | 認識する言語（自動検出の場合は空欄） | 自動検出 |
| プロンプト | 認識精度向上のためのヒント | なし |

### ステップ2: テキスト要約（OpenAI GPT-4）

| 設定項目 | 説明 | デフォルト値 |
|---------|------|------------|
| モデル | 使用する言語モデル | gpt-4 |
| 温度 | 生成の多様性（低いほど決定的） | 0.7 |
| 最大トークン | 生成するテキストの最大長 | 1000 |
| システムプロンプト | AIの役割と指示 | 「あなたは音声の書き起こしを要約するアシスタントです。以下の書き起こしテキストを簡潔に要約してください。」 |

### 入出力の流れ

1. ユーザーが音声ファイルをアップロード
2. Whisperが音声をテキストに変換
3. 変換されたテキストがGPT-4に送信される
4. GPT-4がテキストを要約
5. 要約結果がユーザーに表示される

### 使用例

- 会議の録音から重要ポイントを抽出
- 講義やセミナーの内容を要約
- インタビューの内容を簡潔にまとめる

---

## リンク分析＆図解化

このフローは、ウェブページの内容を分析し、その内容を図解化します。

### ステップ1: リンク分析（Perplexity）

| 設定項目 | 説明 | デフォルト値 |
|---------|------|------------|
| モード | 検索モード | answer |
| 詳細レベル | 分析の詳細度 | detailed |
| 最大トークン | 分析結果の最大長 | 2000 |
| 温度 | 生成の多様性 | 0.5 |

### ステップ2: 図解化（Anthropic Claude）

| 設定項目 | 説明 | デフォルト値 |
|---------|------|------------|
| モデル | 使用する言語モデル | claude-3-sonnet |
| 温度 | 生成の多様性 | 0.7 |
| 最大トークン | 生成するテキストの最大長 | 1500 |
| システムプロンプト | AIの役割と指示 | 「あなたは情報を図解化するエキスパートです。提供された情報を元に、マークダウン形式で図解を作成してください。図解には、主要な概念、関係性、プロセスを含めてください。」 |

### 入出力の流れ

1. ユーザーがURLを入力
2. PerplexityがURLの内容を分析・要約
3. 分析結果がClaudeに送信される
4. Claudeが内容を図解化（マークダウン形式）
5. 図解結果がユーザーに表示される

### 使用例

- 技術記事の内容を図解化して理解を深める
- 複雑なウェブページの情報を視覚的に整理
- 学習リソースの内容を構造化して記憶しやすくする

---

## 検索＆図解化

このフローは、検索クエリに基づいて情報を収集し、その結果を図解化します。

### ステップ1: ウェブ検索（Perplexity）

| 設定項目 | 説明 | デフォルト値 |
|---------|------|------------|
| モード | 検索モード | search |
| 詳細レベル | 検索結果の詳細度 | detailed |
| 最大トークン | 検索結果の最大長 | 2000 |
| 温度 | 生成の多様性 | 0.5 |
| 言語 | 検索結果の言語 | 日本語 |

### ステップ2: 図解化（Anthropic Claude）

| 設定項目 | 説明 | デフォルト値 |
|---------|------|------------|
| モデル | 使用する言語モデル | claude-3-sonnet |
| 温度 | 生成の多様性 | 0.7 |
| 最大トークン | 生成するテキストの最大長 | 1500 |
| システムプロンプト | AIの役割と指示 | 「あなたは情報を図解化するエキスパートです。提供された検索結果を元に、マークダウン形式で図解を作成してください。図解には、主要な概念、関係性、プロセスを含めてください。」 |

### 入出力の流れ

1. ユーザーが検索クエリを入力
2. Perplexityが検索を実行し、結果を要約
3. 検索結果がClaudeに送信される
4. Claudeが検索結果を図解化（マークダウン形式）
5. 図解結果がユーザーに表示される

### 使用例

- 特定のトピックに関する情報を視覚的にまとめる
- 複数の情報源からの知識を統合して構造化
- 学習や研究のための概念マップを作成

---

## YouTube動画分析

このフローは、YouTube動画の内容を分析・要約します。

### ステップ1: YouTube動画取得（YouTube API）

| 設定項目 | 説明 | デフォルト値 |
|---------|------|------------|
| タイプ | 取得するコンテンツタイプ | video |
| 並び順 | 検索結果の並び順 | relevance |
| 最大結果数 | 取得する結果の数 | 1 |
| 字幕言語 | 取得する字幕の言語 | 自動検出 |
| 地域 | コンテンツの地域設定 | JP |

### ステップ2: 動画内容分析（OpenAI GPT-4）

| 設定項目 | 説明 | デフォルト値 |
|---------|------|------------|
| モデル | 使用する言語モデル | gpt-4 |
| 温度 | 生成の多様性 | 0.5 |
| 最大トークン | 生成するテキストの最大長 | 1000 |
| システムプロンプト | AIの役割と指示 | 「あなたはYouTube動画の内容を分析するアシスタントです。提供された字幕情報を元に、動画の内容を要約し、主要なポイントをリストアップしてください。」 |

### 入出力の流れ

1. ユーザーがYouTube動画のURLを入力
2. YouTube APIが動画情報と字幕を取得
3. 字幕情報がGPT-4に送信される
4. GPT-4が動画内容を分析・要約
5. 分析結果がユーザーに表示される

### 使用例

- 長い講義やプレゼンテーション動画の内容を素早く把握
- 教育コンテンツの主要ポイントを抽出
- 複数の関連動画の内容を比較・分析

---

## 会議議事録作成

このフローは、会議の音声から議事録を自動作成します。

### ステップ1: 音声認識（OpenAI Whisper）

| 設定項目 | 説明 | デフォルト値 |
|---------|------|------------|
| モデル | 使用する音声認識モデル | whisper-1 |
| 温度 | 生成の多様性 | 0.0 |
| 言語 | 認識する言語 | 自動検出 |
| プロンプト | 認識精度向上のためのヒント | 「これは会議の録音です」 |

### ステップ2: 議事録作成（Anthropic Claude）

| 設定項目 | 説明 | デフォルト値 |
|---------|------|------------|
| モデル | 使用する言語モデル | claude-3-opus |
| 温度 | 生成の多様性 | 0.3 |
| 最大トークン | 生成するテキストの最大長 | 2000 |
| システムプロンプト | AIの役割と指示 | 「あなたは会議の議事録を作成するプロフェッショナルです。提供された会議の書き起こしから、以下の形式で議事録を作成してください：<br><br># 会議議事録<br><br>## 基本情報<br>- 日時：[日時]<br>- 参加者：[参加者リスト]<br><br>## アジェンダ<br>[主要なアジェンダ項目]<br><br>## 議論内容<br>[主要な議論ポイント]<br><br>## 決定事項<br>[会議で決定された事項]<br><br>## アクションアイテム<br>[フォローアップが必要な項目と担当者]<br><br>## 次回会議<br>[次回会議の予定（もし言及されていれば）]」 |

### 入出力の流れ

1. ユーザーが会議の音声ファイルをアップロード
2. Whisperが音声をテキストに変換
3. 変換されたテキストがClaudeに送信される
4. Claudeがテキストから構造化された議事録を作成
5. 議事録がユーザーに表示される

### 使用例

- 定例会議の議事録を自動作成
- リモート会議の内容を記録・整理
- プロジェクトミーティングの決定事項とアクションアイテムを明確化

---

## 翻訳＆要約

このフローは、外国語のテキストを翻訳し、その内容を要約します。

### ステップ1: 翻訳（DeepL）

| 設定項目 | 説明 | デフォルト値 |
|---------|------|------------|
| 対象言語 | 翻訳先の言語 | JA（日本語） |
| フォーマリティ | 翻訳の丁寧さレベル | default |
| 用語集 | 特定の用語の翻訳ルール | なし |
| タグ処理 | HTMLタグの処理方法 | ignore |

### ステップ2: 要約（OpenAI GPT-3.5）

| 設定項目 | 説明 | デフォルト値 |
|---------|------|------------|
| モデル | 使用する言語モデル | gpt-3.5-turbo |
| 温度 | 生成の多様性 | 0.5 |
| 最大トークン | 生成するテキストの最大長 | 800 |
| システムプロンプト | AIの役割と指示 | 「あなたは翻訳されたテキストを要約するアシスタントです。提供されたテキストを簡潔に要約し、主要なポイントをリストアップしてください。」 |

### 入出力の流れ

1. ユーザーが外国語テキストを入力
2. DeepLがテキストを日本語に翻訳
3. 翻訳されたテキストがGPT-3.5に送信される
4. GPT-3.5がテキストを要約
5. 翻訳と要約結果がユーザーに表示される

### 使用例

- 外国語の記事や論文を素早く理解
- 国際的なニュースの内容を把握
- 外国語の製品マニュアルやドキュメントの要点を抽出

---

## 画像生成＆説明

このフローは、AIで画像を生成し、その画像の説明を自動作成します。

### ステップ1: 画像生成（Stability AI）

| 設定項目 | 説明 | デフォルト値 |
|---------|------|------------|
| モデル | 使用する画像生成モデル | stable-diffusion-xl |
| ステップ数 | 生成プロセスのステップ数 | 30 |
| CFGスケール | プロンプトへの忠実度 | 7 |
| 幅 | 生成画像の幅 | 1024 |
| 高さ | 生成画像の高さ | 1024 |
| サンプラー | 使用するサンプリング方法 | K_EULER_ANCESTRAL |
| シード | 生成の再現性のための値 | ランダム |

### ステップ2: 画像説明（Anthropic Claude）

| 設定項目 | 説明 | デフォルト値 |
|---------|------|------------|
| モデル | 使用する言語モデル | claude-3-haiku |
| 温度 | 生成の多様性 | 0.7 |
| 最大トークン | 生成するテキストの最大長 | 500 |
| システムプロンプト | AIの役割と指示 | 「あなたは生成された画像を説明するアシスタントです。画像の内容、スタイル、雰囲気などを詳細に説明してください。」 |

### 入出力の流れ

1. ユーザーが画像生成プロンプトを入力
2. Stability AIがプロンプトに基づいて画像を生成
3. 生成された画像がClaudeに送信される
4. Claudeが画像の詳細な説明を作成
5. 画像と説明がユーザーに表示される

### 使用例

- クリエイティブなコンテンツ制作
- ビジュアルコンセプトの探索と説明
- アクセシビリティ向上のための画像説明生成
